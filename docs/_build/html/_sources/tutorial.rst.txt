Full worked tutorial
====================

**whyqd** was developed to solve a daily, grinding need in our `Sqwyre.com <https://sqwyre.com>`_
project. Every quarter, we import about 300 very messy spreadsheets from local authorities across
the UK. These need to be restructured to conform to a single schema, including redefining
whatever weird terms they use to describe categorical data, and only then can we begin the automated
process of cleaning and validating the data.

**Sqwyre** is an online market intelligence service helping you assess opportunities and risks for
every commercial property in England and Wales. Our data wrangling process requires that we import
data, including the business name, address and occupation status of every commercial ratepayer, in
whatever format it is released, and align it to a single schema before bulk-uploading it into our
database. It's a mostly free service, so you can see it in action at `Sqwyre.com <https://sqwyre.com>`_.

When we started, this was a purely manual process but, gradually, we developed what has become
**whyqd**. The process, at a high level, is as follows:

  - Create, update or import a data schema which defines the destination data structure
  - Create a new method and associate it with your schema and input data source/s
  - Assign a foreign key column and (if required) merge input data sources
  - Structure input data fields to conform to the requriements for each schema field
  - Assign categorical data identified during structuring
  - Filter and transform input data to produce a final destination data file

You are more likely to create your schema at the beginning of a project, and then spend most of your
time using that schema as the base for creating new methods for each new data source. If you're really
lucky, your data source won't change their own methods from release-to-release and you can reuse your
own methods. In our experience that is like searching for unicorns.

The example in our worked tutorial is derived directly from our workflow at Sqwyre.com and is from a
dataset released by `Portsmouth City Council <https://www.portsmouth.gov.uk/ext/business/running-a-business/business-rates-foi-requests>`_.
The data in this tutorial are from January 2020, but follow along with the current download.

.. note:: This tutorial does assume familiarity with Python and Pandas, and a little experience with JSON.

Creating a Schema
-----------------

Review the :doc:`schema` documentation for more details. We'll start by importing **whyqd**
and defining a new schema::

	import whyqd as _w
	schema = _w.Schema()

The objective of your schema is not only to define a structure for your data, but also provide
reference and contextual information for anyone using it. In a research context, definitions are
critical to avoid ambiguity, ensure replication, and build trust.

The minimum requirement for a schema is that it have a `name`, but we're going to give it a `title`
and `description` as well, because more information is better. We're not barbarians::

	details = {
		"name": "rates_data_schema",
		"title": "UK Ratepayer data schema",
		"description": "Structural metadata target for imported messy data from the 348 local authorities in England & Wales."
	}
	schema.set_details(**details)

We can also save our schema to a specified `directory`::

	directory = "/path/to/directory"
	# you can also specify an optional filename
	# if you leave it out, the filename will default to the schema name
	filename = "2020_rates_data_schema"
	# if the file already exists, you'll need to specify `overwrite=True` otherwise you'll get
	# an error
	schema.save(directory, filename=filename, overwrite=True)

We'll now start to create each of our schema `fields`.

.. note:: You can think of a schema `field` as a `column` in a table, or a `field` in a database. Fields have a `type`, such as integer or text.

Each field, unsurprisingly, has a `name`, `title` and `description`, of which only the `name` is required.
Fields also have a `type`. This describes the data expected and limits the actions which can be performed
during the wrangling process.

We want our destination data to conform to the following structure::

	=========  ============  =============  ========  ================  =====================  =============  ========================
	  la_code        ba_ref  occupant_name  postcode  occupation_state  occupation_state_date  prop_ba_rates  occupation_state_reliefs
	=========  ============  =============  ========  ================  =====================  =============  ========================
	E06000044  177500080710  A company       PO5 2SE              True             2019-04-01          98530  [small_business, retail]
	=========  ============  =============  ========  ================  =====================  =============  ========================

Each of these fields is a different `type` of data:

* `string`: any text-based string.
* `number`: any number-based value, including integers and floats.
* `integer`: any integer-based value.
* `boolean`: a boolean [`true`, `false`] value. Can set category constraints to fix term used.
* `object`: any valid JSON data.
* `array`: any valid array-based data.
* `date`: any date without a time. Must be in ISO8601 format, `YYYY-MM-DD`.
* `datetime`: any date with a time. Must be in ISO8601 format, with UTC time specified (optionally) as `YYYY-MM-DD hh:mm:ss Zz`.
* `year`: any year, formatted as `YYYY`.

In addition, these data can be `constrained`:

* `required`: boolean, indicates whether this field is compulsory (but blank values in the input column are permitted and will be set to the `missing` default)
* `unique`: boolean, if `true` then all values for that input column must be unique
* `minimum`: `integer` / `number`, as appropriate defining min number of characters in a string, or the min values of numbers or integers
* `maximum`: `integer` / `number`, as appropriate defining max number of characters in a string, or the max values of numbers or integers
* `category`: the set of unique category terms permitted in this field
* `filter`: limit a named field by date-limited data

We'll go through most of these in the tutorial. Note that some of these are only there to support
post-wrangling (such as `minimum` or `maximum`). `required` means that a method won't be validated
if that field has no data.

We'll build a single dictionary and then iterate over the list to add each field::

	fields = [
		{
			"name": "la_code",
			"title": "Local authority code",
			"type": "string",
			"description": "Standard code for local authority."
		},
		{
			"name": "ba_ref",
			"title": "Billing reference",
			"type": "string",
			"description": "Unique code for a specific hereditament. May be multiple rows for history."
		},
		{
			"name": "prop_ba_rates",
			"title": "Property billing rates",
			"type": "number",
			"description": "Actual rates paid by a specific ratepayer."
		},
		{
			"name": "occupant_name",
			"title": "Occupier name",
			"type": "string",
			"description": "Name of the ratepayer."
		},
		{
			"name": "postcode",
			"title": "Postcode",
			"type": "string",
			"description": "Full address or postcode of ratepayer."
		},
		{
			"name": "occupation_state",
			"title": "Occupation state",
			"type": "boolean",
			"description": "Occupation status, void or occupied."
		},
		{
			"name": "occupation_state_date",
			"title": "Date of occupation state",
			"type": "date",
			"description": "Date of the start of status in occupation_state."
		},
		{
			"name": "occupation_state_reliefs",
			"title": "Occupation state reliefs",
			"type": "array",
			"description": "Array of the categories of reliefs / exemptions applied."
		}
	]
	for field in fields:
		schema.set_field(**field)

From here on we can access any `field` by calling it by `name` and then edit it as required::

	schema.field("occupation_state_reliefs")

	{'name': 'occupation_state_reliefs',
	 'type': 'array',
	 'title': 'Occupation state reliefs',
	 'description': 'Array of the categories of reliefs / exemptions applied.'}

Let's add a list of `category` terms as a constraint for `occupation_state_reliefs`::

	categories = ["small_business", "rural", "charity", "enterprise_zone", "vacancy", "hardship", "retail", "discretionary", "exempt", "transitional", "other"]
	schema.set_field_category("occupation_state_reliefs", *categories)
	schema.field("occupation_state_reliefs")

	{'name': 'occupation_state_reliefs',
	 'type': 'array',
	 'constraints': {'category': [{'name': 'small_business'},
	   {'name': 'rural'},
	   {'name': 'charity'},
	   {'name': 'enterprise_zone'},
	   {'name': 'vacancy'},
	   {'name': 'hardship'},
	   {'name': 'retail'},
	   {'name': 'discretionary'},
	   {'name': 'exempt'},
	   {'name': 'transitional'},
	   {'name': 'other'}]},
	 'title': 'Occupation state reliefs',
	 'description': 'Array of the categories of reliefs / exemptions applied.'}
